{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9af5e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-Python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\student\\anaconda3\\lib\\site-packages (from opencv-Python) (1.26.4)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/39.5 MB 8.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 3.1/39.5 MB 8.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 8.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 7.1/39.5 MB 8.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 8.9/39.5 MB 8.8 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.7/39.5 MB 8.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 12.8/39.5 MB 8.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 14.7/39.5 MB 8.8 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.5/39.5 MB 8.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.4/39.5 MB 8.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 20.4/39.5 MB 8.8 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 22.3/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.1/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.2/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.0/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.9/39.5 MB 8.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.7/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.6/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.7/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.5/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 7.7 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-Python\n",
      "Successfully installed opencv-Python-4.11.0.86\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48831b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fa3c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c824884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cc480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the image\n",
    "image_path = \"Car.jpg\"  # Replace with your image path\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Step 2: Resize the image (optional based on your requirements)\n",
    "target_size = (640, 480)  # Resize to a fixed size\n",
    "image = cv2.resize(image, target_size)\n",
    "\n",
    "# Step 3: Convert to Grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 4: Apply Gaussian Blur to reduce noise\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Step 5: Edge Detection using Canny\n",
    "edges = cv2.Canny(blurred_image, 100, 200)\n",
    "\n",
    "# Step 6: Thresholding (optional)\n",
    "_, threshold_image = cv2.threshold(edges, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Step 7: Morphological Transformations\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "dilated_image = cv2.dilate(threshold_image, kernel, iterations=1)\n",
    "\n",
    "# Optional: Other Morphological Operations like Erosion\n",
    "# eroded_image = cv2.erode(threshold_image, kernel, iterations=1)\n",
    "\n",
    "# Step 8: Optional - Histogram Equalization to improve contrast\n",
    "equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "# Displaying the images to visually inspect\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Grayscale Image', gray_image)\n",
    "cv2.imshow('Blurred Image', blurred_image)\n",
    "cv2.imshow('Edges', edges)\n",
    "cv2.imshow('Threshold Image', threshold_image)\n",
    "cv2.imshow('Dilated Image', dilated_image)\n",
    "cv2.imshow('Equalized Image', equalized_image)\n",
    "\n",
    "# Wait for a key press to close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6a21e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the video capture\n",
    "video_path = \"Drone.mp4\"  # Replace with your video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize the FAST detector and ORB descriptor\n",
    "fast = cv2.FastFeatureDetector_create(threshold=25)  # FAST detector\n",
    "orb = cv2.ORB_create()  # ORB detector and descriptor\n",
    "\n",
    "# Parameters for the motion tracking (you can adjust this)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Initialize variables for tracking keypoints across frames\n",
    "prev_frame = None\n",
    "prev_keypoints = None\n",
    "prev_descriptors = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to grayscale (ORB and FAST work on grayscale images)\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect keypoints and descriptors on the current frame using ORB\n",
    "    keypoints = fast.detect(gray_frame, None)\n",
    "    keypoints, descriptors = orb.compute(gray_frame, keypoints)\n",
    "\n",
    "    # Draw the keypoints on the current frame for visualization\n",
    "    frame_with_keypoints = cv2.drawKeypoints(frame, keypoints, None, color=(0, 255, 0))\n",
    "\n",
    "    if prev_frame is not None:\n",
    "        # Use the good features to track (using Lucas-Kanade optical flow)\n",
    "        prev_pts = np.array([kp.pt for kp in prev_keypoints], dtype=np.float32).reshape(-1, 1, 2)\n",
    "        curr_pts, status, error = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "\n",
    "        # Flatten status array to 1D\n",
    "        status = status.reshape(-1)\n",
    "\n",
    "        # Filter the points based on the status (only keep points that were tracked successfully)\n",
    "        good_new = curr_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "\n",
    "        # Draw lines and points to indicate the motion of the tracked features\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = old.ravel()  # Convert old points from 2D array to flat coordinates\n",
    "            c, d = new.ravel()  # Convert new points from 2D array to flat coordinates\n",
    "            frame_with_keypoints = cv2.line(frame_with_keypoints, (int(a), int(b)), (int(c), int(d)), (0, 0, 255), 2)\n",
    "            frame_with_keypoints = cv2.circle(frame_with_keypoints, (int(c), int(d)), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Show the frame with the keypoints and motion tracking\n",
    "    cv2.imshow(\"Motion Tracking\", frame_with_keypoints)\n",
    "\n",
    "    # Update previous frame and keypoints for next iteration\n",
    "    prev_frame = gray_frame\n",
    "    prev_keypoints = keypoints\n",
    "    prev_descriptors = descriptors\n",
    "\n",
    "    # Break the loop on 'Esc' key press\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the MRI image (replace with your own MRI image file)\n",
    "image_path = \"Brain.jpg\"  # Replace with your image file path\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Step 1: Preprocessing - Remove noise using Gaussian Blur\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Step 2: Apply Histogram Equalization for contrast enhancement\n",
    "equalized_image = cv2.equalizeHist(blurred_image)\n",
    "\n",
    "# Step 3: Thresholding - Separate tumor from brain tissue\n",
    "# Use Otsu's thresholding to automatically find a good threshold value\n",
    "_, thresholded_image = cv2.threshold(equalized_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Step 4: Find contours to identify tumor regions\n",
    "contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Step 5: Filter small contours (you may adjust the area threshold as needed)\n",
    "min_area = 500  # Minimum contour area to be considered a tumor\n",
    "tumor_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "\n",
    "# Step 6: Draw the contours on the original image\n",
    "output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to BGR for visualization\n",
    "cv2.drawContours(output_image, tumor_contours, -1, (0, 255, 0), 2)  # Draw green contours\n",
    "\n",
    "# Step 7: Post-processing - Apply morphological operations to refine the result (optional)\n",
    "kernel = np.ones((5, 5), np.uint8)  # Define a kernel for dilation\n",
    "dilated_image = cv2.dilate(thresholded_image, kernel, iterations=2)  # Dilation to join small tumor parts\n",
    "\n",
    "# Show the results\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Preprocessed Image\", equalized_image)\n",
    "cv2.imshow(\"Thresholded Image\", thresholded_image)\n",
    "cv2.imshow(\"Tumor Contours\", output_image)\n",
    "cv2.imshow(\"Dilated Image\", dilated_image)\n",
    "\n",
    "# Wait for a key press and close the image windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
